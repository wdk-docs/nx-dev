# 计算缓存

> 在阅读本指南之前，请先阅读[心智模型指南](/using-nx/mental-model).
> 它将帮助您理解计算缓存如何适应 Nx 的其余部分。

## 概述

一遍又一遍地重建和重新测试相同的代码代价很高。
Nx 使用计算缓存来避免两次重建相同的代码。
它是这样做的:

在运行任何任务之前，Nx 都会计算它的计算哈希。
只要计算哈希是相同的，运行任务的输出是相同的。

默认情况下，`nx test app1` 的计算哈希包括:

- `app1` 的所有源文件及其依赖项
- 相关全局配置
- 外部依赖的版本
- 用户提供的运行时值，例如 Node 的版本
- CLI 命令标志

![computation-hashing](/shared/mental-model/computation-hashing.png)

此行为是可定制的。
例如，lint 检查可能只依赖于项目的源代码和全局配置。
构建可以依赖于已编译库的 dts 文件，而不是它们的源代码。

在 Nx 为一个任务计算哈希之后，它会检查之前是否运行了这个精确的计算。
首先，它在本地进行检查，
然后，如果它丢失了，并且配置了远程缓存，它就进行远程检查。

如果 Nx 找到了计算，Nx 将检索并重播它。
Nx 将正确的文件放在正确的文件夹中，并打印终端输出。
所以从用户的角度来看，命令运行的速度是一样的，只是快了很多。

![cache](/shared/mental-model/cache.png)

如果 Nx 没有找到这个计算，Nx 就运行这个任务，在它完成之后，它获取输出和终端输出，并将其存储在本地(如果是远程配置的话)。
所有这些都是透明的，所以你不用担心。

尽管从概念上讲，这是相当简单的，但 Nx 对其进行了优化，使其对您有好处。
例如,Nx:

- 捕获标准输出和标准错误，以确保重播输出看起来相同，包括在 Windows 上。
- 通过记住哪些文件在哪里被重放来最小化 IO。
- 仅在处理大型任务图时显示相关输出。
- 为故障诊断缓存丢失提供可视性。还有很多其他的优化。

随着工作空间的增长，任务图看起来更像这样:

![cache](/shared/mental-model/task-graph-big.png)

所有这些优化对于使 Nx 可用于任何重要的工作空间至关重要。
只做了最少量的工作。
其余部分要么保持原样，要么从缓存中恢复。

## 源代码哈希输入

The result of building/testing an application or a library depends on the source code of that project and all the source codes of all the libraries it depends on (directly or indirectly).
It also depends on the configuration files like `package.json`, `workspace.json`, `nx.json`, `tsconfig.base.json`, and `package-lock.json`.
The list of these files isn't arbitrary.
Nx can deduce most of them by analyzing our codebase.
Few have to be listed manually in the `implicitDependencies` property of `nx.json`.

```json
{
  "npmScope": "happyorg",
  "implicitDependencies": {
    "global-config-file.json": "*"
  },
  "tasksRunnerOptions": {
    "default": {
      "options": {
        "cacheableOperations": ["build", "test", "lint", "e2e"]
      }
    }
  }
}
```

## 运行时散列输入

All commands listed in `runtimeCacheInputs` are invoked by Nx, and the results are included into the computation hash of each task.

```json
{
  "npmScope": "happyorg",
  "tasksRunnerOptions": {
    "default": {
      "options": {
        "cacheableOperations": ["build", "test", "lint", "e2e"],
        "runtimeCacheInputs": ["node -v", "echo $IMPORTANT_ENV_VAR"]
      }
    }
  }
}
```

Sometimes the amount of _runtimeCacheInputs_ can be too overwhelming and difficult to read or parse.
In this case, we
recommend creating a `SHA` from those inputs.
It can be done like the following:

```json
{
  "npmScope": "happyorg",
  "tasksRunnerOptions": {
    "default": {
      "options": {
        "cacheableOperations": ["build", "test", "lint", "e2e"],
        "runtimeCacheInputs": [
          "node -v",
          "echo $IMPORTANT_ENV_VAR",
          "echo $LONG_IMPORTANT_ENV_VAR | sha256sum",
          "cat path/to/my/big-list-of-checksums.txt | sha256sum"
        ]
      }
    }
  }
}
```

## Args 散列输入

Finally, in addition to Source Code Hash Inputs and Runtime Hash Inputs, Nx needs to consider the arguments: For example, `nx build shop` and `nx build shop --prod` produce different results.

Note, only the flags passed to the executor itself affect results of the computation.
For instance, the following commands are identical from the caching perspective.

```bash
nx build myapp --prod
nx build myapp --configuration=production
nx run-many --target=build --projects=myapp --configuration=production
nx run-many --target=build --projects=myapp --configuration=production --parallel
nx affected:build # given that myapp is affected
```

In other words, Nx does not cache what the developer types into the terminal.
The args cache inputs consist of: Project Name, Target, Configuration + Args Passed to Executors.

If you build/test/lint… multiple projects, each individual build has its own hash value and is either be retrieved from cache or run.
This means that from the caching point of view, the following command:

```bash
nx run-many --target=build --projects=myapp1,myapp2
```

is identical to the following two commands:

```bash
nx build myapp1
nx build myapp2
```

## 什么是缓存

Nx works on the process level.
Regardless of the tools used to build/test/lint/etc..
your project, the results is cached.

Nx sets up hooks to collect stdout/stderr before running the command.
All the output is cached and then replayed during a cache hit.

Nx also caches the files generated by a command.
The list of folders is listed in the `outputs` property.

```json
{
  "projects": {
    "myapp": {
      "root": "apps/myapp/",
      "sourceRoot": "apps/myapp/src",
      "projectType": "application",
      "architect": {
        "build": {
          "builder": "@nrwl/js:tsc",
          "outputs": ["dist/apps/myapp"],
          "options": {
            "main": "apps/myapp/src/index.ts"
          }
        }
      }
    }
  }
}
```

If the `outputs` property is missing, Nx defaults to caching the appropriate folder in the dist (`dist/apps/myapp` for `myapp` and `dist/libs/somelib` for `somelib`).

## 忽略缓存

Sometimes you want to skip the cache, such as if you are measuring the performance of a command.
Use the `--skip-nx-cache` flag to skip checking the computation cache.

```bash
nx build myapp --skip-nx-cache
nx affected --target=build --skip-nx-cache
```

## 自定义缓存位置

The cache is stored in `node_modules/.cache/nx` by default.
To change the cache location, update the `cacheDirectory` option for the task runner:

```json
{
  "npmScope": "happyorg",
  "tasksRunnerOptions": {
    "default": {
      "options": {
        "cacheableOperations": ["build", "test", "lint", "e2e"],
        "cacheDirectory": "/tmp/nx"
      }
    }
  }
}
```

## 本地计算缓存

By default, Nx uses a local computation cache.
Nx stores the cached values only for a week, after which they are deleted.
To clear the cache run `nx reset`, and Nx creates a new one the next time it tries to access it.

## 分布式计算缓存

The computation cache provided by Nx can be distributed across multiple machines.
Nx Cloud is a product that allows you to share the results of running build/test with everyone else working in the same workspace.
Learn more at [https://nx.app](https://nx.app).

You can connect your workspace to Nx Cloud by running:

```bash
nx connect-to-nx-cloud
```

You can also distribute the cache manually using your own storage mechanisms.

## 例子

- [这是一个示例 repo](https://github.com/vsavkin/large-monorepo)基准测试 Nx 的计算缓存。
  这也解释了为什么 Nx 的计算缓存往往比其他构建系统的缓存快得多。
